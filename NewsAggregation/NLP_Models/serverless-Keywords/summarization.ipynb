{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2921538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model_path = './model'\n",
    "# initialize the model architecture and weights\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "# initialize the model tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d68e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "A frontal boundary that had been stalled over the mid-Atlantic had lifted north of the region by the morning of \n",
    "June 29. Later that day and into the evening, the front once again approached, this time as a strong cold front,\n",
    "as low pressure tracked through New England and began to intensify offshore in the Gulf of Maine. \n",
    "The combination of strong frontal forcing and a warm, unstable environment ahead of the front led to \n",
    "widespread severe thunderstorms developing. Numerous reports of damaging wind, as well as some hail, \n",
    "were received in association with these storms.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ab4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the text into tensor of integers using the appropriate tokenizer\n",
    "inputs = tokenizer.encode(\"summarize: \" + article, return_tensors=\"pt\", max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1411c40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     3,     9,   851,    24,   141,   118,     3,  8407,  1361,\n",
      "           147,     8,  2076,    18,   188,    17,  1618,  1225, 19464,  3457,\n",
      "            13,     8,  1719,     3,     5,   865,    24,   239,    11,   139,\n",
      "             8,  2272,     6,     8,   851,   728,   541, 15319,     3,     5,\n",
      "           731,  1666, 22679,   190,   126,  2789,    11,  1553,    12,  9608,\n",
      "          4921, 16667,    16,     8, 13566,    13, 13905,     3,     5,     1]])\n",
      "<pad> a front that had been stalled over the mid-Atlantic lifted north of the region. later that day and into the evening, the front once again approached. low pressure tracked through new England and began to intensify offshore in the Gulf of Maine.</s>\n"
     ]
    }
   ],
   "source": [
    "# generate the summarization output\n",
    "outputs = model.generate(\n",
    "    inputs, \n",
    "    max_length=150, \n",
    "    min_length=40, \n",
    "    length_penalty=2.0, \n",
    "    num_beams=4, \n",
    "    early_stopping=True)\n",
    "# just for debugging\n",
    "print(outputs)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72d18d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, AutoConfig\n",
    "\n",
    "def serverless_pipeline(model_path='./model'):\n",
    "    # initialize the model architecture and weights\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "    # initialize the model tokenizer\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "    def predict(context):\n",
    "        \"\"\"predicts the answer on an given question and context. Uses encode and decode method from above\"\"\"\n",
    "        # encode the text into tensor of integers using the appropriate tokenizer\n",
    "        inputs = tokenizer.encode(\"summarize: \" + context, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        outputs = model.generate(\n",
    "                inputs, \n",
    "                max_length=150, \n",
    "                min_length=40, \n",
    "                length_penalty=2.0, \n",
    "                num_beams=4, \n",
    "                early_stopping=True)\n",
    "        answer = tokenizer.decode(outputs[0])\n",
    "        return answer\n",
    "    return predict\n",
    "\n",
    "# initializes the pipeline\n",
    "question_answering_pipeline = serverless_pipeline()\n",
    "\n",
    "def handler(event, context):\n",
    "    try:\n",
    "        # loads the incoming event into a dictonary\n",
    "        body = json.loads(event['body'])\n",
    "        # uses the pipeline to predict the answer\n",
    "        answer = question_answering_pipeline(context=body['context'])\n",
    "        return {\n",
    "            \"statusCode\": 200,\n",
    "            \"headers\": {\n",
    "                'Content-Type': 'application/json',\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                \"Access-Control-Allow-Credentials\": True\n",
    "\n",
    "            },\n",
    "            \"body\": json.dumps({'answer': answer})\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(repr(e))\n",
    "        return {\n",
    "            \"statusCode\": 500,\n",
    "            \"headers\": {\n",
    "                'Content-Type': 'application/json',\n",
    "                'Access-Control-Allow-Origin': '*',\n",
    "                \"Access-Control-Allow-Credentials\": True\n",
    "            },\n",
    "            \"body\": json.dumps({\"error\": repr(e)})\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cc527af",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = question_answering_pipeline(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c5a103b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> a front that had been stalled over the mid-Atlantic lifted north of the region. later that day and into the evening, the front once again approached. low pressure tracked through new England and began to intensify offshore in the Gulf of Maine.</s>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bdddd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('.venv': venv)",
   "language": "python",
   "name": "python380jvsc74a57bd0b4268bdeb8b3cd6119633cfedec5f8ccd1d344ae93aca82ac0bac4da2ecd2271"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
